{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Dec 17 16:57:25 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64       Driver Version: 440.64       CUDA Version: 10.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  TITAN RTX           Off  | 00000000:03:00.0 Off |                  N/A |\n",
      "| 43%   63C    P2    94W / 280W |   3843MiB / 24219MiB |      7%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  TITAN RTX           Off  | 00000000:04:00.0 Off |                  N/A |\n",
      "| 41%   39C    P8     4W / 280W |     12MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  TITAN RTX           Off  | 00000000:82:00.0 Off |                  N/A |\n",
      "| 41%   38C    P8     5W / 280W |   1455MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  TITAN RTX           Off  | 00000000:83:00.0 Off |                  N/A |\n",
      "| 41%   38C    P8    15W / 280W |   3081MiB / 24220MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#! unzip 00000.zip \n",
    "#! unzip \"01000.zip\"\n",
    "#! unzip \"without_mask.zip\"\n",
    "#! unzip \"with_mask.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! mv \"./00000/\" \"./corr\"\n",
    "#! mv \"./01000/\" \"./incorr\"\n",
    "#!rm ./without_mask/.DS_Store\n",
    "#!cp -a ./with_mask/. ./corr/\n",
    "#!rm ./corr/.DS_Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport shutil\\n\\nwith open(outfilename, 'wb') as outfile:\\n    for filename in glob.glob('*.txt'):\\n        if filename == outfilename:\\n            # don't want to copy the output into the output\\n            continue\\n        with open(filename, 'rb') as readfile:\\n            shutil.copyfileobj(readfile, outfile)\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import shutil\n",
    "\n",
    "with open(outfilename, 'wb') as outfile:\n",
    "    for filename in glob.glob('*.txt'):\n",
    "        if filename == outfilename:\n",
    "            # don't want to copy the output into the output\n",
    "            continue\n",
    "        with open(filename, 'rb') as readfile:\n",
    "            shutil.copyfileobj(readfile, outfile)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs_corr = list(sorted(os.listdir(os.path.join(root, \"corr\"))))\n",
    "        self.imgs_incor = list(sorted(os.listdir(os.path.join(root, \"incorr\"))))\n",
    "        self.no_mask = list(sorted(os.listdir(os.path.join(root, \"without_mask\"))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        if idx < len(self.imgs_corr):\n",
    "            img_path = os.path.join(self.root, \"corr\", self.imgs_corr[idx])\n",
    "            target = 1\n",
    "        elif idx < len(self.imgs_corr) + len(self.imgs_incor):\n",
    "            img_path = os.path.join(self.root, \"incorr\", self.imgs_incor[idx - len(self.imgs_corr)])\n",
    "            target = 0\n",
    "        else:\n",
    "            img_path = os.path.join(self.root, \"without_mask\", self.no_mask[idx - len(self.imgs_corr) -\\\n",
    "                                                                                  len(self.imgs_incor)])\n",
    "            target = 2\n",
    "        \n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(img)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_corr) + len(self.imgs_incor) + len(self.no_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset('./')\n",
    "img, t = dataset[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5740"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.RandomCrop((input_size, input_size)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(7),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "#тест не меняем\n",
    "test_tf = transforms.Compose([\n",
    "    transforms.Resize(input_size),\n",
    "    transforms.RandomCrop((input_size, input_size)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = CustomDataset('./', train_tf)\n",
    "dataset_test = CustomDataset('./', test_tf)\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-300])\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-300:])\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "    dataset_test, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5440"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device we will work on: cuda:1\n"
     ]
    }
   ],
   "source": [
    "## specify the GPU id's, GPU id's start from 0.\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device we will work on:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "model = models.alexnet(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#В качестве лоса возмем кросс-энтропию. Оптимизатор - Адам\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1.0e-3)\n",
    "\n",
    "#добавим уменьшение лернинг рейта, если выходим на плато. Это решение будем принимать по валидационной выборке.\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=7, factor=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_ftrs = model.classifier[6].in_features\n",
    "model.classifier[6] = nn.Linear(num_ftrs, num_classes)\n",
    "input_size = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 57,016,131 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, trainloader, testloader):\n",
    "    running_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    test_acc = 0.0\n",
    "    len_train = 0.0\n",
    "    len_test = 0.0\n",
    "    \n",
    "    loss_train = 0.0\n",
    "  \n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss_val = loss(outputs, targets)\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "        accuracy_add = (outputs.argmax(dim=1) == targets).float().sum().data.cpu()\n",
    "        train_acc += accuracy_add\n",
    "        len_train += len(targets)\n",
    "        loss_train += len(targets) * loss_val.item()\n",
    "        running_loss += loss_val.item()\n",
    "        \n",
    "    for _, (inputs, targets) in enumerate(testloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        outputs = model(inputs)\n",
    "        accuracy_add = (outputs.argmax(dim=1) == targets).float().sum().data.cpu()\n",
    "        test_acc += accuracy_add\n",
    "        len_test += len(targets)\n",
    "\n",
    "        \n",
    "    lr_scheduler.step(running_loss)\n",
    "\n",
    "    return train_acc / len_train, test_acc / len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/PIL/Image.py:961: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1    acc_train: 0.7178    test_acc: 0.8433    time: 293.80\n",
      "Epoch: 2    acc_train: 0.861    test_acc: 0.8867    time: 252.63\n",
      "Epoch: 3    acc_train: 0.8858    test_acc: 0.87    time: 317.64\n",
      "Epoch: 4    acc_train: 0.8886    test_acc: 0.8467    time: 292.62\n",
      "Epoch: 5    acc_train: 0.9199    test_acc: 0.9167    time: 231.42\n",
      "Epoch: 6    acc_train: 0.9287    test_acc: 0.9367    time: 347.81\n",
      "Epoch: 7    acc_train: 0.9401    test_acc: 0.9233    time: 370.06\n",
      "Epoch: 8    acc_train: 0.934    test_acc: 0.8633    time: 335.14\n",
      "Epoch: 9    acc_train: 0.9276    test_acc: 0.9167    time: 242.20\n",
      "Epoch: 10    acc_train: 0.945    test_acc: 0.9367    time: 267.58\n"
     ]
    }
   ],
   "source": [
    "accuracy_history_test = []\n",
    "accuracy_history_train = []\n",
    "\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    start_time = time() \n",
    "    train_acc, test_acc = train(epoch, data_loader, data_loader_test)\n",
    "    accuracy_history_test.append(test_acc)\n",
    "    accuracy_history_train.append(train_acc)\n",
    "    acc_train = np.round(train_acc.numpy(), 4)\n",
    "    acc_test = np.round(test_acc.numpy (), 4)\n",
    "    print('Epoch:', epoch+1, '   acc_train:', acc_train, '   test_acc:', acc_test, '   time: %.2f'%(time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.save(model, 'alexnet.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
